{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLpl6A1X1S5JY5cHq29xzv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usamireko/WFL-ASR/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install and Preparation\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output, display, Javascript\n",
        "drive.mount('/content/drive')\n",
        "message = \"\"\"\n",
        "alert(\"Installing components for inference\");\n",
        "\"\"\"\n",
        "!git clone https://github.com/MLo7Ghinsan/WFL-ASR\n",
        "!wget https://github.com/MLo7Ghinsan/WFL-ASR/releases/download/model_release/model_1.0.zip\n",
        "!unzip model_1.0.zip -d /content/model\n",
        "%cd /content/WFL-ASR\n",
        "display(Javascript(message))\n",
        "!pip install -r requirements.txt\n",
        "clear_output()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H2NPv3kbnymV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply settings\n",
        "%%writefile /content/model/config.yaml\n",
        "\n",
        "data:\n",
        "  data_dir: /content/Training_dataset\n",
        "  sample_rate: 16000\n",
        "  num_val_files: 10\n",
        "  max_seq_len: null\n",
        "model:\n",
        "  encoder_type: whisper\n",
        "  whisper_model: openai/whisper-base\n",
        "  wavlm_model: microsoft/wavlm-base\n",
        "  freeze_encoder: false\n",
        "  enable_bilstm: true\n",
        "  bilstm_num_layer: 2\n",
        "  enable_dilated_conv: true\n",
        "  dilated_conv_depth: 2\n",
        "  dilated_conv_kernel: 3\n",
        "  enable_duration_prediction: true\n",
        "  duration_head_dim: 128\n",
        "  duration_loss_weight: 0.2\n",
        "  enable_self_attn_polisher: false\n",
        "  self_attn_heads: 2\n",
        "  num_conformer_layers: 2\n",
        "  conformer_heads: 2\n",
        "  conformer_ff_expansion: 2\n",
        "  conformer_kernel_size: 31\n",
        "  conformer_dropout: 0.5\n",
        "  lang_emb_dim: 64\n",
        "  num_languages: 2\n",
        "training:\n",
        "  batch_size: 1\n",
        "  num_workers: 4\n",
        "  learning_rate: 0.0000001\n",
        "  weight_decay: 1.0e-05\n",
        "  label_smoothing: 0.1\n",
        "  max_steps: 500000\n",
        "  val_check_interval: 1000\n",
        "  max_checkpoints: 5\n",
        "  log_dir: /content/logs\n",
        "output:\n",
        "  save_dir: /content/model\n",
        "postprocess:\n",
        "  median_filter: 2\n",
        "  merge_segments: previous\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wXl5qwXdvsn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "English data == 0 as lang_id\n",
        "Japanese data == 1 as lang_id"
      ],
      "metadata": {
        "id": "kgTu51YItLnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Single Audio Inference\n",
        "import os\n",
        "audio_file = \"\" # @param {\"type\":\"string\"}\n",
        "lang_id = \"1\" # @param [\"0\",\"1\"]\n",
        "name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "output_lab = \"/content/drive/MyDrive/data/\" + name + \".lab\"\n",
        "!python infer.py {audio_file} /content/model/best_model.pt /content/model/config.yaml {output_lab} --lang_id {lang_id}\n",
        "clear_output()\n",
        "print(\"Labels generated, check them under \" + output_lab)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yGWa2fGKoBOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Folder Inference\n",
        "folder_path = \"\" # @param {\"type\":\"string\"}\n",
        "lang_id = \"1\" # @param [\"0\",\"1\"]\n",
        "output_path = folder_path + \"/labs\"\n",
        "!python infer.py --folder {folder_path} /content/model/best_model.pt /content/model/config.yaml {output_path}  --lang_id {lang_id}\n",
        "clear_output()\n",
        "print(\"Labels generated, check them under \" + output_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SET_mLXjs06N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}